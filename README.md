<div id="top" align="center">
  <img src="https://media.giphy.com/media/LmN8EsTEjS8LgtxP9X/giphy.gif" alt="Data Transformation GIF" width="100"/>
  <h1>Proyecto ETL: Automatizaci√≥n de Constancias de Entrenamiento y Preparaci√≥n de Datos RRHH</h1>
  <h3>Un pipeline ETL robusto para transformar datos de entrenamiento y recursos humanos en insights accionables.</h3>
</div>

<br>

## üìÑ Tabla de Contenidos

*   [Acerca del Proyecto](#acerca-del-proyecto)
*   [El Problema](#el-problema)
*   [La Soluci√≥n: Nuestro Pipeline ETL](#la-soluci√≥n-nuestro-pipeline-etl)
    *   [Visi√≥n General de la Configuraci√≥n Centralizada](#visi√≥n-general-de-la-configuraci√≥n-centralizada)
    *   [1. Identificaci√≥n y Filtro de Archivos (`generador_lista_no_excluidos.py`)](#1-identificaci√≥n-y-filtro-de-archivos-generador_lista_no_excluidospy)
    *   [2. Extracci√≥n, Transformaci√≥n y Carga de Constancias (`etl_pdf_entrenamiento.py`)](#2-extracci√≥n-transformaci√≥n-y-carga-de-constancias-etl_pdf_entrenamientopy)
    *   [3. Preparaci√≥n de Tablas Maestras para Dashboards (`etl_bd_hc.py`)](#3-preparaci√≥n-de-tablas-maestras-para-dashboards-etl_bd_hcpy)
*   [Tecnolog√≠as Utilizadas](#tecnolog√≠as-utilizadas)
*   [Estado Actual y Futuro](#estado-actual-y-futuro)
*   [Estructura del Proyecto](#estructura-del-proyecto)
*   [Contribuci√≥n](#contribuci√≥n)
*   [Contacto](#contacto)

---

## üéØ Acerca del Proyecto

Este proyecto implementa un pipeline ETL (Extracci√≥n, Transformaci√≥n y Carga) completo dise√±ado para automatizar el procesamiento de constancias de entrenamiento en formato PDF y la consolidaci√≥n de diversas fuentes de datos de Recursos Humanos. El objetivo final es generar informaci√≥n limpia, estructurada y lista para ser consumida en dashboards interactivos, facilitando la toma de decisiones estrat√©gicas en √°reas como la gesti√≥n del talento, ausentismo y cobertura operacional.

## ‚ö†Ô∏è El Problema

Tradicionalmente, el manejo de constancias de entrenamiento implicaba tareas manuales repetitivas y propensas a errores, como:
*   B√∫squeda manual de nuevos archivos PDF en m√∫ltiples ubicaciones.
*   Filtrado manual de constancias irrelevantes o duplicadas.
*   Extracci√≥n manual de datos clave (nombre, curso, fecha, instructor, grupo) de cada PDF.
*   Consolidaci√≥n de esta informaci√≥n con datos de empleados.
*   Organizaci√≥n f√≠sica de los PDFs en carpetas espec√≠ficas.
*   Preparaci√≥n y limpieza de diversas bases de datos de RRHH (maestro HC, bajas, asistencia, cobertura).

Estos procesos consum√≠an mucho tiempo y recursos, impidiendo una visi√≥n √°gil y precisa del estado del entrenamiento y el capital humano.

## ‚úÖ La Soluci√≥n: Nuestro Pipeline ETL

Nuestro proyecto aborda estos desaf√≠os a trav√©s de una arquitectura modular compuesta por tres scripts principales que trabajan en conjunto para automatizar todo el flujo de datos, orquestados por un script `main.py`.

### Visi√≥n General de la Configuraci√≥n Centralizada

Una mejora fundamental en este pipeline es la introducci√≥n de la clase `Config`. Esta clase centraliza **todas las rutas de archivos, nombres de carpetas, nombres de hojas de c√°lculo, reglas de exclusi√≥n y mapeos de texto** utilizados en los diferentes scripts ETL. Al cargar una √∫nica instancia de `Config` al inicio del proceso, se logra:
*   **Mantenibilidad:** Facilita la actualizaci√≥n de rutas y par√°metros en un solo lugar.
*   **Consistencia:** Asegura que todos los scripts utilicen los mismos valores de configuraci√≥n.
*   **Robustez:** Simplifica la gesti√≥n de dependencias y evita la dispersi√≥n de la l√≥gica de configuraci√≥n.
*   **Preparaci√≥n del Entorno:** Se encarga de crear las carpetas de salida necesarias, tanto locales como en OneDrive, para asegurar que el pipeline pueda almacenar sus resultados sin problemas.

Cada funci√≥n del pipeline ahora recibe el objeto `Config`, lo que garantiza que operen con un conjunto coherente y actualizado de par√°metros.

### 1. Identificaci√≥n y Filtro de Archivos (`generador_lista_no_excluidos.py`)

Este script act√∫a como la **primera fase de descubrimiento**. Su funci√≥n es escanear recursivamente las carpetas fuente definidas (a trav√©s del objeto `Config`), aplicando un conjunto de reglas de exclusi√≥n para directorios y archivos PDF.
*   **Escaneo Inteligente:** Recorre las `source_folders_pdfs` buscando archivos PDF.
*   **Reglas de Exclusi√≥n:** Filtra archivos y directorios bas√°ndose en `excluded_prefixes`, `excluded_suffixes`, `non_vigentes_years_in_filename` (a√±os no vigentes en el nombre del archivo) y la fecha de √∫ltima modificaci√≥n (`min_mod_year`, ej. excluyendo archivos anteriores a 2024).
*   **Detecci√≥n de Archivos Procesados:** Utiliza un log persistente (`registro_archivos_procesados.txt`, gestionado en memoria por `processed_files_set_in_memory` en `Config`) para identificar y saltar archivos que ya fueron procesados previamente, asegurando que solo se trabajen con "archivos nuevos no excluidos".
*   **Identificaci√≥n de PDFs Agrupados:** Determina si un PDF es "agrupado" (m√∫ltiples p√°ginas, indicando varias constancias en un solo archivo) o "standalone" (una constancia por archivo).
*   **Output:** Genera un archivo `lista_pdfs_nuevos_no_excluidos.txt` que contiene las rutas de los PDFs que necesitan ser procesados, junto con un flag indicando si son agrupados o individuales.

### 2. Extracci√≥n, Transformaci√≥n y Carga de Constancias (`etl_pdf_entrenamiento.py`)

Este es el **coraz√≥n del proceso ETL de constancias**. Toma la lista generada por el script anterior y realiza la extracci√≥n detallada y la transformaci√≥n de los datos, utilizando el objeto `Config` para todos sus par√°metros internos.
*   **Gesti√≥n de Carpetas de Bajas (`mover_carpetas_bajas`):** Una nueva funcionalidad clave es la identificaci√≥n y movimiento autom√°tico de carpetas de empleados con estatus 'BAJA' (seg√∫n el `hc_table.csv`) desde la ruta de certificados activos (`onedrive_certs_active`) a una subcarpeta de bajas (`onedrive_certs_bajas`). Esto asegura una organizaci√≥n de archivos limpia y evita el procesamiento innecesario de certificados de personal inactivo. Se incluye una robusta funci√≥n `rmtree_onerror_retry` para manejar errores de permisos al eliminar carpetas en el destino.
*   **Manejo de PDFs Agrupados:** Divide autom√°ticamente los PDFs agrupados en archivos temporales individuales, procesando cada constancia de forma independiente. La l√≥gica de divisi√≥n ha sido mejorada para omitir p√°ginas que no contienen certificados v√°lidos, optimizando el procesamiento.
*   **Extracci√≥n de Datos Avanzada (`extraer_datos_constancia`):** Emplea expresiones regulares (`re`) y la librer√≠a `PyMuPDF (fitz)` para extraer de forma robusta el nombre del empleado, curso, fecha, instructor y grupo de diferentes formatos de constancias (determinados por `nombres_archivos_sat`, `nombres_archivos_sms`, `nombres_archivos_avsec`).
*   **Normalizaci√≥n y Homologaci√≥n (`normalizar_acentos`, `homologar_curso`):** Limpia y normaliza los nombres de los empleados, cursos e instructores (ej. eliminando acentos usando `vocales_acentos`, espacios extra), y **homologa** los nombres de los cursos a categor√≠as est√°ndar (ej. "SAT(Rampa)", "AVSEC", "SMS").
*   **Parseo de Fechas (`parse_fecha_inicio`):** Extrae y normaliza las fechas de los cursos, incluso manejando diferentes formatos y rangos (usando `mapeo_meses`), para calcular la fecha de vigencia y asignar un `estatus_vigencia` (Vigente/Vencido).
*   **Integraci√≥n con HC (`procesar_y_mergear_constancias`):** Realiza un proceso de **doble merge** con una tabla maestra de empleados (cargada con `cargar_data_hc` desde `hc_table_path`) para asociar cada constancia a un n√∫mero de empleado (`#emp`) y su estatus. Se implementan estrategias de coincidencia robustas para nombres, intentando m√∫ltiples formatos para maximizar las coincidencias.
*   **Filtrado de Negocio:** Aplica reglas de negocio para descartar constancias espec√≠ficas (ej. por instructor, nombre de archivo, prefijos de grupo) o eliminar duplicados, garantizando la calidad de los datos finales.
*   **Generaci√≥n de Nombres Est√°ndar:** Crea nombres de archivo estandarizados y limpios (`nombre_archivo_nuevo`) para las constancias procesadas (ej. `CURSO_DD-MM-YYYY_NOMBRE_COMPLETO.pdf`).
*   **Organizaci√≥n Autom√°tica de Archivos (`organizar_archivos_pdf`):** Copia los PDFs procesados a una estructura de carpetas `[N√∫mero de Empleado]` dentro de `onedrive_certs_active` o `onedrive_certs_bajas`, seg√∫n el estatus del empleado. El `original_source_path` del archivo fuente original (sea agrupado o standalone) se registra para evitar futuros reprocesamientos.
*   **Reporte de No Coincidencias (`identificar_y_reportar_constancias_sin_coincidencia`):** Identifica y exporta las constancias que no pudieron ser asociadas a un n√∫mero de empleado a archivos espec√≠ficos (`datos_constancias_sin_emp.xlsx` y `datos_constancias_sin_emp.csv`), facilitando la revisi√≥n manual.
*   **Intelligent Export/Consolidation (`exportar_resultados`):** Esta funci√≥n ha sido mejorada para cargar datos existentes (`datos_constancias.xlsx` y `datos_constancias.csv`), concatenar los nuevos registros, y luego **eliminar duplicados** bas√°ndose en un subconjunto de columnas clave. Esto asegura que los archivos de salida est√©n siempre actualizados, contengan un historial completo y est√©n libres de entradas redundantes, incluso despu√©s de m√∫ltiples ejecuciones. Incluye formato avanzado para Excel.
*   **Output:** Exporta el historial consolidado de constancias a archivos `datos_constancias.xlsx` y `datos_constancias.csv` con formato. Mantiene actualizado el `registro_archivos_procesados.txt`. Realiza limpieza de la carpeta de PDFs temporales (`temp_split_pdfs_folder`) al inicio y al final de la ejecuci√≥n.

### 3. Preparaci√≥n de Tablas Maestras para Dashboards (`etl_bd_hc.py`)

Este script se encarga de procesar y estructurar diversas fuentes de datos de Recursos Humanos, generando tablas limpias y desnormalizadas, listas para ser consumidas directamente por un dashboard de inteligencia de negocios. Al igual que los otros scripts, utiliza el objeto `Config` para acceder a todas las rutas de archivos, nombres de hojas de c√°lculo (`hc_etl_sheets_names`) y mapeos de acentos (`vocales_acentos`).
*   **Carga y Limpieza Gen√©rica:** Utiliza funciones gen√©ricas (`cargar_transformar_excel`, `cargar_transformar_csv`) para cargar y limpiar datos de archivos Excel y CSV, normalizando nombres de columnas y eliminando duplicados. Incluye funciones espec√≠ficas para `limpiar_columna_texto`, `limpiar_columna_id` y `limpiar_columna_fecha`.
*   **Procesamiento de Datos Maestros:**
    *   **`hc_table`**: Carga y limpia la base de datos maestra de capital humano desde `FILE_MAESTRO_HC`, creando una columna de `nombre_completo` estandarizada y normalizando campos como IDs y fechas.
    *   **`hc_bajas_table`**: Procesa los registros de empleados dados de baja desde la hoja 'BAJAS_HC'.
    *   **`puestos_table`**: Crea una tabla de dimensiones para cargos/puestos homologados (desde `FILE_PUESTOS`), incluyendo detalles como √°rea y horas diarias.
    *   **`cursos_table`**: Genera una tabla de dimensiones para los cursos de entrenamiento a partir de `FILE_ENTRENAMIENTO`.
    *   **`asistencia_table`**: Consolida los registros de asistencia a entrenamientos a partir de la hoja 'Programacion' de `FILE_ENTRENAMIENTO`.
    *   **`ausentismo_table`**: Procesa los datos de faltas y ausentismo del reloj checador, iterando sobre los archivos CSV en `FOLDER_RELOJ_CHECADOR`.
    *   **`cobertura_table`**: Prepara los datos relacionados con la cobertura de personal y requerimientos de puestos desde `FILE_COBERTURA`.
*   **Integraci√≥n de Datos:** Realiza merges clave para enriquecer las tablas (ej. uniendo el maestro HC con los datos adicionales y los puestos homologados).
*   **Output:** Exporta m√∫ltiples archivos CSV a la carpeta `dashboard_tables_folder` (definida en `Config`), listos para ser conectados a herramientas como Power BI o Tableau, siguiendo los nombres de archivo especificados en `hc_etl_out_filenames`.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

*   **Python 3.x:** Lenguaje principal de desarrollo.
*   **Pandas:** Para manipulaci√≥n y an√°lisis de datos en DataFrames.
*   **PyMuPDF (fitz):** Para extracci√≥n eficiente de texto de documentos PDF.
*   **`re` (Regular Expressions):** Para patrones de b√∫squeda avanzados y extracci√≥n de datos en texto.
*   **`os`, `shutil`, `datetime`, `unicodedata`, `numpy`, `stat`:** M√≥dulos est√°ndar de Python para operaciones de sistema, manejo de archivos/carpetas (incluyendo cambios de permisos), fechas y num√©ricas.
*   **XlsxWriter (a trav√©s de `pandas.ExcelWriter`):** Para la exportaci√≥n de DataFrames a Excel con formato personalizado (encabezados, anchos de columna, autofiltros).

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python Badge"/>
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas Badge"/>
  <img src="https://img.shields.io/badge/PyMuPDF-000000?style=for-the-badge&logo=pdf&logoColor=white" alt="PyMuPDF Badge"/>
  <img src="https://img.shields.io/badge/Regular%20Expressions-FF9900?style=for-the-badge&logo=regex&logoColor=white" alt="Regex Badge"/>
  <img src="https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white" alt="Git Badge"/>
</p>

## üöÄ Estado Actual y Futuro

El proyecto se encuentra en una **fase avanzada de proceso y refinamiento**. Actualmente, los scripts son funcionales y demuestran la capacidad de automatizar de manera efectiva la extracci√≥n, transformaci√≥n y carga de datos. Las recientes mejoras en la configuraci√≥n centralizada, el manejo de archivos de bajas, la deduplicaci√≥n inteligente de datos y el reporte detallado han aumentado significativamente su robustez y fiabilidad.

**Pr√≥ximos Pasos:**
*   **Empaquetamiento:** Se planea empaquetar el proyecto para facilitar su despliegue y uso en diferentes entornos.
*   **Interfaz Gr√°fica de Usuario (GUI):** La futura implementaci√≥n de una GUI permitir√° a usuarios no t√©cnicos interactuar con el pipeline de forma intuitiva, facilitando la configuraci√≥n de rutas y la ejecuci√≥n de los procesos con solo unos clics. Esto mejorar√° significativamente la usabilidad y accesibilidad del sistema.

## üìÅ Estructura del Proyecto
* 
* ‚îú‚îÄ‚îÄ data/
* ‚îÇ ‚îú‚îÄ‚îÄ processed/
* ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ dashboard_tables/ # Tablas limpias para dashboards (CSV)
* ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ fact_table.csv
* ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ hc_table.csv
* ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ hc_bajas_table.csv
* ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ puestos_table.csv
* ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ cursos_table.csv
* ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ asistencia_table.csv
* ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ausentismo_table.csv
* ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ cobertura_table.csv
* ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ temp_split_pdfs/ # PDFs temporales generados al dividir agrupados (limpiada en cada ejecuci√≥n)
* ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ datos_constancias.xlsx # Historial consolidado de constancias
* ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ datos_constancias.csv # Historial consolidado de constancias
* ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ datos_constancias_sin_emp.xlsx # Constancias sin #emp asignado (para revisi√≥n)
* ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ datos_constancias_sin_emp.csv # Constancias sin #emp asignado (para revisi√≥n)
* ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ registro_archivos_procesados.txt # Log de archivos fuente procesados
* ‚îÇ ‚îî‚îÄ‚îÄ raw/ # Fuentes de datos originales (no generada por el script)
* ‚îú‚îÄ‚îÄ src/
* ‚îÇ ‚îú‚îÄ‚îÄ config.py # Clase de configuraci√≥n centralizada
* ‚îÇ ‚îú‚îÄ‚îÄ etl_bd_hc.py # Script para la preparaci√≥n de tablas de HC para dashboards
* ‚îÇ ‚îú‚îÄ‚îÄ etl_pdf_entrenamiento.py # Script principal ETL de constancias PDF
* ‚îÇ ‚îú‚îÄ‚îÄ generador_lista_no_excluidos.py # Script para identificar y filtrar nuevos PDFs
* ‚îÇ ‚îî‚îÄ‚îÄ init.py # Archivo de inicializaci√≥n del paquete src
* ‚îú‚îÄ‚îÄ main.py # Orquestador principal del pipeline ETL
* ‚îî‚îÄ‚îÄ README.md

## ü§ù Contribuci√≥n

Actualmente, el proyecto se mantiene de forma individual. Si est√°s interesado en contribuir o tienes sugerencias, no dudes en contactarme.

## üìû Contacto

Puedes conectar conmigo a trav√©s de mi perfil de LinkedIn:

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/bryan-betancur-420103255/)