<div id="top" align="center">
  <img src="https://media.giphy.com/media/LmN8EsTEjS8LgtxP9X/giphy.gif" alt="Data Transformation GIF" width="100"/>
  <h1>Proyecto ETL: AutomatizaciÃ³n de Constancias de Entrenamiento y PreparaciÃ³n de Datos RRHH</h1>
  <h3>Un pipeline ETL robusto para transformar datos de entrenamiento y recursos humanos en insights accionables.</h3>
</div>

<br>

## ğŸ“„ Tabla de Contenidos

*   [Acerca del Proyecto](#acerca-del-proyecto)
*   [El Problema](#el-problema)
*   [La SoluciÃ³n: Nuestro Pipeline ETL](#la-soluciÃ³n-nuestro-pipeline-etl)
    *   [1. IdentificaciÃ³n y Filtro de Archivos (`generador_lista_no_excluidos.py`)](#1-identificaciÃ³n-y-filtro-de-archivos-generador_lista_no_excluidospy)
    *   [2. ExtracciÃ³n, TransformaciÃ³n y Carga de Constancias (`etl_pdf_entrenamiento.py`)](#2-extracciÃ³n-transformaciÃ³n-y-carga-de-constancias-etl_pdf_entrenamientopy)
    *   [3. PreparaciÃ³n de Tablas Maestras para Dashboards (`etl_bd_hc.py`)](#3-preparaciÃ³n-de-tablas-maestras-para-dashboards-etl_bd_hcpy)
*   [TecnologÃ­as Utilizadas](#tecnologÃ­as-utilizadas)
*   [Estado Actual y Futuro](#estado-actual-y-futuro)
*   [Estructura del Proyecto](#estructura-del-proyecto)
*   [ContribuciÃ³n](#contribuciÃ³n)
*   [Contacto](#contacto)

---

## ğŸ¯ Acerca del Proyecto

Este proyecto implementa un pipeline ETL (ExtracciÃ³n, TransformaciÃ³n y Carga) completo diseÃ±ado para automatizar el procesamiento de constancias de entrenamiento en formato PDF y la consolidaciÃ³n de diversas fuentes de datos de Recursos Humanos. El objetivo final es generar informaciÃ³n limpia, estructurada y lista para ser consumida en dashboards interactivos, facilitando la toma de decisiones estratÃ©gicas en Ã¡reas como la gestiÃ³n del talento, ausentismo y cobertura operacional.

## âš ï¸ El Problema

Tradicionalmente, el manejo de constancias de entrenamiento implicaba tareas manuales repetitivas y propensas a errores, como:
*   BÃºsqueda manual de nuevos archivos PDF en mÃºltiples ubicaciones.
*   Filtrado manual de constancias irrelevantes o duplicadas.
*   ExtracciÃ³n manual de datos clave (nombre, curso, fecha, instructor, grupo) de cada PDF.
*   ConsolidaciÃ³n de esta informaciÃ³n con datos de empleados.
*   OrganizaciÃ³n fÃ­sica de los PDFs en carpetas especÃ­ficas.
*   PreparaciÃ³n y limpieza de diversas bases de datos de RRHH (maestro HC, bajas, asistencia, cobertura).

Estos procesos consumÃ­an mucho tiempo y recursos, impidiendo una visiÃ³n Ã¡gil y precisa del estado del entrenamiento y el capital humano.

## âœ… La SoluciÃ³n: Nuestro Pipeline ETL

Nuestro proyecto aborda estos desafÃ­os a travÃ©s de una arquitectura modular compuesta por tres scripts principales que trabajan en conjunto para automatizar todo el flujo de datos.

### 1. IdentificaciÃ³n y Filtro de Archivos (`generador_lista_no_excluidos.py`)

Este script actÃºa como la **primera fase de descubrimiento**. Su funciÃ³n es escanear recursivamente las carpetas fuente definidas, aplicando un conjunto de reglas de exclusiÃ³n para directorios y archivos PDF.
*   **Escaneo Inteligente:** Recorre las carpetas fuente buscando archivos PDF.
*   **Reglas de ExclusiÃ³n:** Filtra archivos y directorios basÃ¡ndose en prefijos, sufijos, aÃ±os no vigentes en el nombre del archivo y la fecha de Ãºltima modificaciÃ³n (ej. excluyendo archivos anteriores a 2024).
*   **DetecciÃ³n de Archivos Procesados:** Utiliza un log de `registro_archivos_procesados.txt` para identificar y saltar archivos que ya fueron procesados previamente, asegurando que solo se trabajen con "archivos nuevos no excluidos".
*   **IdentificaciÃ³n de PDFs Agrupados:** Determina si un PDF es "agrupado" (mÃºltiples pÃ¡ginas, indicando varias constancias en un solo archivo) o "standalone" (una constancia por archivo).
*   **Output:** Genera un archivo `lista_pdfs_nuevos_no_excluidos.txt` que contiene las rutas de los PDFs que necesitan ser procesados, junto con un flag indicando si son agrupados o individuales.

### 2. ExtracciÃ³n, TransformaciÃ³n y Carga de Constancias (`etl_pdf_entrenamiento.py`)

Este es el **corazÃ³n del proceso ETL de constancias**. Toma la lista generada por el script anterior y realiza la extracciÃ³n detallada y la transformaciÃ³n de los datos.
*   **GestiÃ³n de ConfiguraciÃ³n:** Utiliza una clase `Config` para centralizar todas las rutas, patrones y parÃ¡metros, facilitando la mantenibilidad.
*   **Manejo de PDFs Agrupados:** Divide automÃ¡ticamente los PDFs agrupados en archivos temporales individuales, procesando cada constancia de forma independiente.
*   **ExtracciÃ³n de Datos Avanzada:** Emplea expresiones regulares (`re`) y la librerÃ­a `PyMuPDF (fitz)` para extraer de forma robusta el nombre del empleado, curso, fecha, instructor y grupo de diferentes formatos de constancias (SAT, SMS, AVSEC).
*   **NormalizaciÃ³n y HomologaciÃ³n:** Limpia y normaliza los nombres de los empleados, cursos e instructores (ej. eliminando acentos, espacios extra), y **homologa** los nombres de los cursos a categorÃ­as estÃ¡ndar (ej. "SAT(Rampa)", "AVSEC", "SMS").
*   **Parseo de Fechas:** Extrae y normaliza las fechas de los cursos, incluso manejando diferentes formatos y rangos, para calcular la fecha de vigencia y asignar un `estatus_vigencia` (Vigente/Vencido).
*   **IntegraciÃ³n con HC:** Realiza un proceso de **doble merge** con una tabla maestra de empleados (HC) para asociar cada constancia a un nÃºmero de empleado (`#emp`) y su estatus. Se implementan estrategias de coincidencia robustas para nombres.
*   **Filtrado de Negocio:** Aplica reglas de negocio para descartar constancias especÃ­ficas (ej. por instructor, nombre de archivo, prefijos de grupo) o eliminar duplicados.
*   **GeneraciÃ³n de Nombres EstÃ¡ndar:** Crea nombres de archivo estandarizados para las constancias procesadas (ej. `CURSO_DD-MM-YYYY_NOMBRE_COMPLETO.pdf`).
*   **OrganizaciÃ³n AutomÃ¡tica de Archivos:** Copia los PDFs procesados a una estructura de carpetas `[NÃºmero de Empleado]`, distinguiendo entre empleados activos y aquellos con estatus de `BAJA` (enviÃ¡ndolos a una subcarpeta especÃ­fica).
*   **Reporte de No Coincidencias:** Identifica y exporta las constancias que no pudieron ser asociadas a un nÃºmero de empleado, facilitando la revisiÃ³n manual.
*   **Output:** Exporta el historial consolidado de constancias a archivos `datos_constancias.xlsx` y `datos_constancias.csv` con formato. Mantiene actualizado el `registro_archivos_procesados.txt`.

### 3. PreparaciÃ³n de Tablas Maestras para Dashboards (`etl_bd_hc.py`)

Este script se encarga de procesar y estructurar diversas fuentes de datos de Recursos Humanos, generando tablas limpias y desnormalizadas, listas para ser consumidas directamente por un dashboard de inteligencia de negocios.
*   **Carga y Limpieza GenÃ©rica:** Utiliza funciones genÃ©ricas para cargar y limpiar datos de archivos Excel y CSV, normalizando nombres de columnas y eliminando duplicados.
*   **Procesamiento de Datos Maestros:**
    *   **`hc_table`**: Carga y limpia la base de datos maestra de capital humano, creando una columna de `nombre_completo` estandarizada y normalizando campos como IDs y fechas.
    *   **`hc_bajas_table`**: Procesa los registros de empleados dados de baja.
    *   **`puestos_table`**: Crea una tabla de dimensiones para cargos/puestos homologados, incluyendo detalles como Ã¡rea y horas diarias.
    *   **`cursos_table`**: Genera una tabla de dimensiones para los cursos de entrenamiento.
    *   **`asistencia_table`**: Consolida los registros de asistencia a entrenamientos.
    *   **`ausentismo_table`**: Procesa los datos de faltas y ausentismo del reloj checador.
    *   **`cobertura_table`**: Prepara los datos relacionados con la cobertura de personal y requerimientos de puestos.
*   **IntegraciÃ³n de Datos:** Realiza merges clave para enriquecer las tablas (ej. uniendo el maestro HC con los puestos homologados).
*   **Output:** Exporta mÃºltiples archivos CSV a la carpeta `data\processed\dashboard_tables`, listos para ser conectados a herramientas como Power BI o Tableau.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

*   **Python 3.x:** Lenguaje principal de desarrollo.
*   **Pandas:** Para manipulaciÃ³n y anÃ¡lisis de datos en DataFrames.
*   **PyMuPDF (fitz):** Para extracciÃ³n eficiente de texto de documentos PDF.
*   **`re` (Regular Expressions):** Para patrones de bÃºsqueda avanzados y extracciÃ³n de datos en texto.
*   **`os`, `shutil`, `datetime`, `unicodedata`, `numpy`:** MÃ³dulos estÃ¡ndar de Python para operaciones de sistema, fechas y numÃ©ricas.
*   **XlsxWriter (a travÃ©s de `pandas.ExcelWriter`):** Para la exportaciÃ³n de DataFrames a Excel con formato personalizado.

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python Badge"/>
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas Badge"/>
  <img src="https://img.shields.io/badge/PyMuPDF-000000?style=for-the-badge&logo=pdf&logoColor=white" alt="PyMuPDF Badge"/>
  <img src="https://img.shields.io/badge/Regular%20Expressions-FF9900?style=for-the-badge&logo=regex&logoColor=white" alt="Regex Badge"/>
  <img src="https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white" alt="Git Badge"/>
</p>

## ğŸš€ Estado Actual y Futuro

El proyecto se encuentra en una **fase avanzada de proceso y refinamiento**. Actualmente, los scripts son funcionales y demuestran la capacidad de automatizar de manera efectiva la extracciÃ³n, transformaciÃ³n y carga de datos.

**PrÃ³ximos Pasos:**
*   **Empaquetamiento:** Se planea empaquetar el proyecto para facilitar su despliegue y uso en diferentes entornos.
*   **Interfaz GrÃ¡fica de Usuario (GUI):** La futura implementaciÃ³n de una GUI permitirÃ¡ a usuarios no tÃ©cnicos interactuar con el pipeline de forma intuitiva, facilitando la configuraciÃ³n de rutas y la ejecuciÃ³n de los procesos con solo unos clics. Esto mejorarÃ¡ significativamente la usabilidad y accesibilidad del sistema.

## ğŸ“ Estructura del Proyecto
* .
* â”œâ”€â”€ data/
* â”‚ â”œâ”€â”€ processed/
* â”‚ â”‚ â”œâ”€â”€ dashboard_tables/ # Tablas limpias para dashboards (CSV)
* â”‚ â”‚ â”œâ”€â”€ Certificados Entrenamiento Viva Handling/ # PDFs organizados por empleado
* â”‚ â”‚ â”‚ â”œâ”€â”€ 0/ # Constancias sin #emp asignado
* â”‚ â”‚ â”‚ â”œâ”€â”€ 0/ # Constancias sin #emp asignado
* â”‚ â”‚ â”‚ â”œâ”€â”€ 12345/ # Ejemplo: Carpeta de empleado 12345 (activos)
* â”‚ â”‚ â”‚ â””â”€â”€ 1. BAJAS/ # Constancias de empleados dados de baja
* â”‚ â”‚ â”‚ â””â”€â”€ 54321/ # Ejemplo: Carpeta de empleado 54321 (baja)
* â”‚ â”‚ â”œâ”€â”€ temp_split_pdfs/ # PDFs temporales generados al dividir agrupados
* â”‚ â”‚ â”œâ”€â”€ datos_constancias.xlsx
* â”‚ â”‚ â”œâ”€â”€ datos_constancias.csv
* â”‚ â”‚ â”œâ”€â”€ datos_constancias_sin_emp.xlsx
* â”‚ â”‚ â”œâ”€â”€ datos_constancias_sin_emp.csv
* â”‚ â”‚ â””â”€â”€ registro_archivos_procesados.txt
* â”‚ â””â”€â”€ raw/ # Fuentes de datos originales
* â”œâ”€â”€ etl_bd_hc.py # Script para la preparaciÃ³n de tablas de HC para dashboards
* â”œâ”€â”€ etl_pdf_entrenamiento.py # Script principal ETL de constancias PDF
* â”œâ”€â”€ generador_lista_no_excluidos.py # Script para identificar y filtrar nuevos PDFs
* â””â”€â”€ README.md

## ğŸ¤ ContribuciÃ³n

Actualmente, el proyecto se mantiene de forma individual. Si estÃ¡s interesado en contribuir o tienes sugerencias, no dudes en contactarme.

## ğŸ“ Contacto

Puedes conectar conmigo a travÃ©s de mi perfil de LinkedIn:

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/bryan-betancur-420103255/)