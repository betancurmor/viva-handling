<div id="top" align="center">
  <img src="https://media.giphy.com/media/LmN8EsTEjS8LgtxP9X/giphy.gif" alt="Data Transformation GIF" width="100"/>
  <h1>Proyecto ETL: Automatizaci√≥n de Constancias de Entrenamiento y Preparaci√≥n de Datos RRHH</h1>
  <h3>Un pipeline ETL robusto para transformar datos de entrenamiento y recursos humanos en insights accionables.</h3>
</div>

<br>

## üìÑ Tabla de Contenidos

*   [Acerca del Proyecto](#acerca-del-proyecto)
*   [El Problema](#el-problema)
*   [La Soluci√≥n: Nuestro Pipeline ETL](#la-soluci√≥n-nuestro-pipeline-etl)
    *   [1. Identificaci√≥n y Filtro de Archivos (`generador_lista_no_excluidos.py`)](#1-identificaci√≥n-y-filtro-de-archivos-generador_lista_no_excluidospy)
    *   [2. Extracci√≥n, Transformaci√≥n y Carga de Constancias (`etl_pdf_entrenamiento.py`)](#2-extracci√≥n-transformaci√≥n-y-carga-de-constancias-etl_pdf_entrenamientopy)
    *   [3. Preparaci√≥n de Tablas Maestras para Dashboards (`etl_bd_hc.py`)](#3-preparaci√≥n-de-tablas-maestras-para-dashboards-etl_bd_hcpy)
*   [Tecnolog√≠as Utilizadas](#tecnolog√≠as-utilizadas)
*   [Estado Actual y Futuro](#estado-actual-y-futuro)
*   [Estructura del Proyecto](#estructura-del-proyecto)
*   [Contribuci√≥n](#contribuci√≥n)
*   [Contacto](#contacto)

---

## üéØ Acerca del Proyecto

Este proyecto implementa un pipeline ETL (Extracci√≥n, Transformaci√≥n y Carga) completo dise√±ado para automatizar el procesamiento de constancias de entrenamiento en formato PDF y la consolidaci√≥n de diversas fuentes de datos de Recursos Humanos. El objetivo final es generar informaci√≥n limpia, estructurada y lista para ser consumida en dashboards interactivos, facilitando la toma de decisiones estrat√©gicas en √°reas como la gesti√≥n del talento, ausentismo y cobertura operacional.

## ‚ö†Ô∏è El Problema

Tradicionalmente, el manejo de constancias de entrenamiento implicaba tareas manuales repetitivas y propensas a errores, como:
*   B√∫squeda manual de nuevos archivos PDF en m√∫ltiples ubicaciones.
*   Filtrado manual de constancias irrelevantes o duplicadas.
*   Extracci√≥n manual de datos clave (nombre, curso, fecha, instructor, grupo) de cada PDF.
*   Consolidaci√≥n de esta informaci√≥n con datos de empleados.
*   Organizaci√≥n f√≠sica de los PDFs en carpetas espec√≠ficas.
*   Preparaci√≥n y limpieza de diversas bases de datos de RRHH (maestro HC, bajas, asistencia, cobertura).

Estos procesos consum√≠an mucho tiempo y recursos, impidiendo una visi√≥n √°gil y precisa del estado del entrenamiento y el capital humano.

## ‚úÖ La Soluci√≥n: Nuestro Pipeline ETL

Nuestro proyecto aborda estos desaf√≠os a trav√©s de una arquitectura modular compuesta por tres scripts principales que trabajan en conjunto para automatizar todo el flujo de datos.

### 1. Identificaci√≥n y Filtro de Archivos (`generador_lista_no_excluidos.py`)

Este script act√∫a como la **primera fase de descubrimiento**. Su funci√≥n es escanear recursivamente las carpetas fuente definidas, aplicando un conjunto de reglas de exclusi√≥n para directorios y archivos PDF.
*   **Escaneo Inteligente:** Recorre las carpetas fuente buscando archivos PDF.
*   **Reglas de Exclusi√≥n:** Filtra archivos y directorios bas√°ndose en prefijos, sufijos, a√±os no vigentes en el nombre del archivo y la fecha de √∫ltima modificaci√≥n (ej. excluyendo archivos anteriores a 2024).
*   **Detecci√≥n de Archivos Procesados:** Utiliza un log de `registro_archivos_procesados.txt` para identificar y saltar archivos que ya fueron procesados previamente, asegurando que solo se trabajen con "archivos nuevos no excluidos".
*   **Identificaci√≥n de PDFs Agrupados:** Determina si un PDF es "agrupado" (m√∫ltiples p√°ginas, indicando varias constancias en un solo archivo) o "standalone" (una constancia por archivo).
*   **Output:** Genera un archivo `lista_pdfs_nuevos_no_excluidos.txt` que contiene las rutas de los PDFs que necesitan ser procesados, junto con un flag indicando si son agrupados o individuales.

### 2. Extracci√≥n, Transformaci√≥n y Carga de Constancias (`etl_pdf_entrenamiento.py`)

Este es el **coraz√≥n del proceso ETL de constancias**. Toma la lista generada por el script anterior y realiza la extracci√≥n detallada y la transformaci√≥n de los datos.
*   **Gesti√≥n de Configuraci√≥n:** Utiliza una clase `Config` para centralizar todas las rutas, patrones y par√°metros, facilitando la mantenibilidad.
*   **Manejo de PDFs Agrupados:** Divide autom√°ticamente los PDFs agrupados en archivos temporales individuales, procesando cada constancia de forma independiente.
*   **Extracci√≥n de Datos Avanzada:** Emplea expresiones regulares (`re`) y la librer√≠a `PyMuPDF (fitz)` para extraer de forma robusta el nombre del empleado, curso, fecha, instructor y grupo de diferentes formatos de constancias (SAT, SMS, AVSEC).
*   **Normalizaci√≥n y Homologaci√≥n:** Limpia y normaliza los nombres de los empleados, cursos e instructores (ej. eliminando acentos, espacios extra), y **homologa** los nombres de los cursos a categor√≠as est√°ndar (ej. "SAT(Rampa)", "AVSEC", "SMS").
*   **Parseo de Fechas:** Extrae y normaliza las fechas de los cursos, incluso manejando diferentes formatos y rangos, para calcular la fecha de vigencia y asignar un `estatus_vigencia` (Vigente/Vencido).
*   **Integraci√≥n con HC:** Realiza un proceso de **doble merge** con una tabla maestra de empleados (HC) para asociar cada constancia a un n√∫mero de empleado (`#emp`) y su estatus. Se implementan estrategias de coincidencia robustas para nombres.
*   **Filtrado de Negocio:** Aplica reglas de negocio para descartar constancias espec√≠ficas (ej. por instructor, nombre de archivo, prefijos de grupo) o eliminar duplicados.
*   **Generaci√≥n de Nombres Est√°ndar:** Crea nombres de archivo estandarizados para las constancias procesadas (ej. `CURSO_DD-MM-YYYY_NOMBRE_COMPLETO.pdf`).
*   **Organizaci√≥n Autom√°tica de Archivos:** Copia los PDFs procesados a una estructura de carpetas `[N√∫mero de Empleado]`, distinguiendo entre empleados activos y aquellos con estatus de `BAJA` (envi√°ndolos a una subcarpeta espec√≠fica).
*   **Reporte de No Coincidencias:** Identifica y exporta las constancias que no pudieron ser asociadas a un n√∫mero de empleado, facilitando la revisi√≥n manual.
*   **Output:** Exporta el historial consolidado de constancias a archivos `datos_constancias.xlsx` y `datos_constancias.csv` con formato. Mantiene actualizado el `registro_archivos_procesados.txt`.

### 3. Preparaci√≥n de Tablas Maestras para Dashboards (`etl_bd_hc.py`)

Este script se encarga de procesar y estructurar diversas fuentes de datos de Recursos Humanos, generando tablas limpias y desnormalizadas, listas para ser consumidas directamente por un dashboard de inteligencia de negocios.
*   **Carga y Limpieza Gen√©rica:** Utiliza funciones gen√©ricas para cargar y limpiar datos de archivos Excel y CSV, normalizando nombres de columnas y eliminando duplicados.
*   **Procesamiento de Datos Maestros:**
    *   **`hc_table`**: Carga y limpia la base de datos maestra de capital humano, creando una columna de `nombre_completo` estandarizada y normalizando campos como IDs y fechas.
    *   **`hc_bajas_table`**: Procesa los registros de empleados dados de baja.
    *   **`puestos_table`**: Crea una tabla de dimensiones para cargos/puestos homologados, incluyendo detalles como √°rea y horas diarias.
    *   **`cursos_table`**: Genera una tabla de dimensiones para los cursos de entrenamiento.
    *   **`asistencia_table`**: Consolida los registros de asistencia a entrenamientos.
    *   **`ausentismo_table`**: Procesa los datos de faltas y ausentismo del reloj checador.
    *   **`cobertura_table`**: Prepara los datos relacionados con la cobertura de personal y requerimientos de puestos.
*   **Integraci√≥n de Datos:** Realiza merges clave para enriquecer las tablas (ej. uniendo el maestro HC con los puestos homologados).
*   **Output:** Exporta m√∫ltiples archivos CSV a la carpeta `data\processed\dashboard_tables`, listos para ser conectados a herramientas como Power BI o Tableau.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

*   **Python 3.x:** Lenguaje principal de desarrollo.
*   **Pandas:** Para manipulaci√≥n y an√°lisis de datos en DataFrames.
*   **PyMuPDF (fitz):** Para extracci√≥n eficiente de texto de documentos PDF.
*   **`re` (Regular Expressions):** Para patrones de b√∫squeda avanzados y extracci√≥n de datos en texto.
*   **`os`, `shutil`, `datetime`, `unicodedata`, `numpy`:** M√≥dulos est√°ndar de Python para operaciones de sistema, fechas y num√©ricas.
*   **XlsxWriter (a trav√©s de `pandas.ExcelWriter`):** Para la exportaci√≥n de DataFrames a Excel con formato personalizado.

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python Badge"/>
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas Badge"/>
  <img src="https://img.shields.io/badge/PyMuPDF-000000?style=for-the-badge&logo=pdf&logoColor=white" alt="PyMuPDF Badge"/>
  <img src="https://img.shields.io/badge/Regular%20Expressions-FF9900?style=for-the-badge&logo=regex&logoColor=white" alt="Regex Badge"/>
  <img src="https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white" alt="Git Badge"/>
</p>

## üöÄ Estado Actual y Futuro

El proyecto se encuentra en una **fase avanzada de proceso y refinamiento**. Actualmente, los scripts son funcionales y demuestran la capacidad de automatizar de manera efectiva la extracci√≥n, transformaci√≥n y carga de datos.

**Pr√≥ximos Pasos:**
*   **Empaquetamiento:** Se planea empaquetar el proyecto para facilitar su despliegue y uso en diferentes entornos.
*   **Interfaz Gr√°fica de Usuario (GUI):** La futura implementaci√≥n de una GUI permitir√° a usuarios no t√©cnicos interactuar con el pipeline de forma intuitiva, facilitando la configuraci√≥n de rutas y la ejecuci√≥n de los procesos con solo unos clics. Esto mejorar√° significativamente la usabilidad y accesibilidad del sistema.

## üìÅ Estructura del Proyecto